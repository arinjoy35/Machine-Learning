{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arinj\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import csv\n",
    "import math\n",
    "import matplotlib.pyplot\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm_notebook                    #importing all packages and libraries\n",
    "from keras.utils import np_utils\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating numpy matrices after feature subtraction and concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../HumanObserved-Dataset/HumanObserved-Features-Data/'\n",
    "hof = pd.read_csv(path + 'HumanObserved-Features-Data.csv', sep=',', header=0, usecols=list(range(1,11)))\n",
    "hof.set_index('img_id', inplace = True)\n",
    "hof_sp = pd.read_csv(path + 'same_pairs.csv', sep=',', header=0, usecols=[0,1])\n",
    "hof_dfn = pd.read_csv(path + 'diffn_pairs.csv', sep=',', header=0, usecols=[0,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hof_sp_concat = np.empty((0,18), int)\n",
    "hof_sp_diff = np.empty((0,9), int)\n",
    "hof_dp_concat = np.empty((0,18), int)\n",
    "hof_dp_diff = np.empty((0,9), int)\n",
    "for i in range(len(hof_sp.index)):\n",
    "    \n",
    "    img_id_A = hof_sp.loc[i][0]\n",
    "    img_id_B = hof_sp.loc[i][1]\n",
    "    concat = np.append(hof.loc[img_id_A], hof.loc[img_id_B])\n",
    "    diff = np.subtract(hof.loc[img_id_A], hof.loc[img_id_B])\n",
    "    hof_sp_concat = np.append(hof_sp_concat, [concat], axis=0)\n",
    "    hof_sp_diff = np.append(hof_sp_diff, [diff], axis=0)\n",
    "\n",
    "np.savetxt('same_pair_concat_pickle.csv', hof_sp_concat, delimiter=',')\n",
    "np.savetxt('same_pair_diff_pickle.csv', hof_sp_diff, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-d46d2b06920e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mconcat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhof\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimg_id_A\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhof\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimg_id_B\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mdiff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhof\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimg_id_A\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhof\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimg_id_B\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mhof_dp_concat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhof_dp_concat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mhof_dp_diff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhof_dp_diff\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdiff\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36mappend\u001b[1;34m(arr, values, axis)\u001b[0m\n\u001b[0;32m   5164\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5165\u001b[0m         \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5166\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#TAKES HUGE TIME TO RUN#\n",
    "\n",
    "for i in range(len(hof_dfn.index)):    \n",
    "    img_id_A = hof_dfn.loc[i][0]\n",
    "    img_id_B = hof_dfn.loc[i][1]\n",
    "    concat = np.append(hof.loc[img_id_A], hof.loc[img_id_B])\n",
    "    diff = np.subtract(hof.loc[img_id_A], hof.loc[img_id_B])\n",
    "    hof_dp_concat = np.append(hof_dp_concat, [concat], axis=0)\n",
    "    hof_dp_diff = np.append(hof_dp_diff, [diff], axis=0)\n",
    "\n",
    "np.savetxt('diff_pair_concat_pickle.csv', hof_dp_concat, delimiter=',')\n",
    "np.savetxt('diff_pair_diff_pickle.csv', hof_dp_diff, delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"same_pair_concat_pickle.csv\" , header=None)\n",
    "df['18'] = '1'\n",
    "df.to_csv('same_pair_concat_pickle_with_ones.csv', header=False, index=False)\n",
    "\n",
    "df = pd.read_csv(\"same_pair_diff_pickle.csv\" , header=None)\n",
    "df['9'] = '1'\n",
    "df.to_csv('same_pair_diff_pickle_with_ones.csv', header=False, index=False)\n",
    "\n",
    "df = pd.read_csv(\"diff_pair_concat_pickle.csv\" , header=None)\n",
    "df['18'] = '0'\n",
    "df.to_csv('diff_pair_concat_pickle_with_zeroes.csv', header=False, index=False)\n",
    "\n",
    "df = pd.read_csv(\"diff_pair_diff_pickle.csv\" , header=None)\n",
    "df['9'] = '0'\n",
    "df.to_csv('diff_pair_diff_pickle_with_zeroes.csv', header=False, index=False)\n",
    "\n",
    "dp_concat_temp = pd.read_csv('diff_pair_concat_pickle_with_zeroes.csv', sep=',')\n",
    "dp_diff_temp = pd.read_csv('diff_pair_diff_pickle_with_zeroes.csv', sep=',')\n",
    "sp_concat_temp = pd.read_csv('same_pair_concat_pickle_with_ones.csv', sep=',')\n",
    "sp_diff_temp = pd.read_csv('same_pair_diff_pickle_with_ones.csv', sep=',')\n",
    "\n",
    "a = np.array(dp_concat_temp[:1210])    #taking total of 2000 data points, 1200 different pairs and 800 same pairs\n",
    "b = np.array(dp_diff_temp[:1210])\n",
    "c = np.array(sp_concat_temp)\n",
    "d = np.array(sp_diff_temp)\n",
    "\n",
    "concat_matrix=np.concatenate((c,a),axis=0)\n",
    "np.random.shuffle(concat_matrix)\n",
    "diff_matrix=np.concatenate((d,b),axis=0)\n",
    "np.random.shuffle(diff_matrix)\n",
    "\n",
    "np.savetxt('concat_matrix_pickle.csv', concat_matrix, delimiter=',')\n",
    "np.savetxt('diff_matrix_pickle.csv', diff_matrix, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partitioning data into training, validation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_con = pd.read_csv('concat_matrix_pickle.csv', sep=',', header=None, usecols=[18])\n",
    "target_vector_concat=np.array(target_con)\n",
    "target_dif = pd.read_csv('diff_matrix_pickle.csv', sep=',', header=None, usecols=[9])\n",
    "target_vector_diff=np.array(target_dif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainingData(given_matrix,given_target):\n",
    "    n, m = given_matrix.shape\n",
    "    n_train = int(0.9 * n)\n",
    "    n_valid = int((n - n_train) / 2)\n",
    "\n",
    "    x_train = given_matrix.loc[:n_train, :]\n",
    "    return x_train\n",
    "\n",
    "def ValidationData(given_matrix,given_target):\n",
    "    n, m = given_matrix.shape\n",
    "    n_train = int(0.9 * n)\n",
    "    n_valid = int((n - n_train) / 2)\n",
    "\n",
    "    x_valid = given_matrix.loc[n_train:n_train + n_valid, :]\n",
    "    return x_valid\n",
    "\n",
    "def TestingData(given_matrix,given_target):\n",
    "    n, m = given_matrix.shape\n",
    "    n_train = int(0.9 * n)\n",
    "    n_valid = int((n - n_train) / 2)\n",
    "\n",
    "    x_test = given_matrix.loc[n_train + n_valid:, :]\n",
    "    return x_test\n",
    "\n",
    "\n",
    "def TrainingVector(given_matrix,given_target):\n",
    "    n, m = given_matrix.shape\n",
    "    n_train = int(0.9 * n)\n",
    "    n_valid = int((n - n_train) / 2)\n",
    "\n",
    "    y_train = given_target[:n_train, :]\n",
    "    return y_train\n",
    "\n",
    "\n",
    "def ValidationVector(given_matrix,given_target):\n",
    "    n, m = given_matrix.shape\n",
    "    n_train = int(0.9 * n)\n",
    "    n_valid = int((n - n_train) / 2)\n",
    "\n",
    "    y_valid = given_target[n_train:n_train + n_valid, :]\n",
    "    return y_valid\n",
    "\n",
    "\n",
    "def TestingVector(given_matrix,given_target):\n",
    "    n, m = given_matrix.shape\n",
    "    n_train = int(0.9 * n)\n",
    "    n_valid = int((n - n_train) / 2)\n",
    "\n",
    "    y_test = given_target[n_train + n_valid:, :]\n",
    "    return y_test\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_data = pd.read_csv('concat_matrix_pickle.csv', sep=',', header=None, usecols=range(18))\n",
    "diff_data = pd.read_csv('diff_matrix_pickle.csv', sep=',', header=None, usecols=range(9))\n",
    "diff_data = diff_data.abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################### Concatenation ##########################\n",
      "(1801, 18)\n",
      "(101, 18)\n",
      "(100, 18)\n",
      "(1800, 1)\n",
      "(100, 1)\n",
      "(100, 1)\n",
      "###################### Subtraction ############################\n",
      "(1801, 9)\n",
      "(101, 9)\n",
      "(100, 9)\n",
      "(1800, 1)\n",
      "(100, 1)\n",
      "(100, 1)\n"
     ]
    }
   ],
   "source": [
    "print('###################### Concatenation ##########################')\n",
    "\n",
    "concat_train_data = TrainingData(concat_data,target_vector_concat) \n",
    "print(concat_train_data.shape)\n",
    "concat_valid_data = ValidationData(concat_data,target_vector_concat) \n",
    "print(concat_valid_data.shape)\n",
    "concat_test_data = TestingData(concat_data,target_vector_concat) \n",
    "print(concat_test_data.shape)\n",
    "concat_train_vector = TrainingVector(concat_data,target_vector_concat) \n",
    "print(concat_train_vector.shape)\n",
    "concat_valid_vector = ValidationVector(concat_data,target_vector_concat) \n",
    "print(concat_valid_vector.shape)\n",
    "concat_test_vector = TestingVector(concat_data,target_vector_concat) \n",
    "print(concat_test_vector.shape)\n",
    "\n",
    "print('###################### Subtraction ############################')\n",
    "\n",
    "diff_train_data = TrainingData(diff_data,target_vector_diff) \n",
    "print(diff_train_data.shape)\n",
    "diff_valid_data = ValidationData(diff_data,target_vector_diff) \n",
    "print(diff_valid_data.shape)\n",
    "diff_test_data = TestingData(diff_data,target_vector_diff) \n",
    "print(diff_test_data.shape)\n",
    "diff_train_vector = TrainingVector(diff_data,target_vector_diff) \n",
    "print(diff_train_vector.shape)\n",
    "diff_valid_vector = ValidationVector(diff_data,target_vector_diff) \n",
    "print(diff_valid_vector.shape)\n",
    "diff_test_vector = TestingVector(diff_data,target_vector_diff) \n",
    "print(diff_test_vector.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxAcc = 0.0\n",
    "maxIter = 0\n",
    "TrainingPercent = 90\n",
    "ValidationPercent = 5\n",
    "TestPercent = 5\n",
    "M = 100\n",
    "PHI = []\n",
    "IsSynthetic = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateBigSigma(Data, MuMatrix,TrainingPercent,IsSynthetic):\n",
    "    BigSigma    = np.zeros((len(Data),len(Data)))\n",
    "    DataT       = np.transpose(Data)\n",
    "    TrainingLen = math.ceil(len(DataT)*(TrainingPercent*0.01))        \n",
    "    varVect     = []\n",
    "    for i in range(0,len(DataT[0])):\n",
    "        vct = []\n",
    "        for j in range(0,int(TrainingLen)):\n",
    "            vct.append(Data[i][j])    \n",
    "        varVect.append(np.var(vct))\n",
    "    \n",
    "    for j in range(len(Data)):\n",
    "        BigSigma[j][j] = varVect[j]\n",
    "    if IsSynthetic == True:\n",
    "        BigSigma = np.dot(3,BigSigma)\n",
    "    else:\n",
    "        BigSigma = np.dot(200,BigSigma)\n",
    "    ##print (\"BigSigma Generated..\")\n",
    "    return BigSigma\n",
    "\n",
    "def GetScalar(DataRow,MuRow, BigSigInv):  \n",
    "    R = np.subtract(DataRow,MuRow)\n",
    "    T = np.dot(BigSigInv,np.transpose(R))  \n",
    "    L = np.dot(R,T)\n",
    "    return L\n",
    "\n",
    "def GetRadialBasisOut(DataRow,MuRow, BigSigInv):    \n",
    "    phi_x = math.exp(-0.5*GetScalar(DataRow,MuRow,BigSigInv))\n",
    "    return phi_x\n",
    "\n",
    "def GetPhiMatrix(Data, MuMatrix, BigSigma, TrainingPercent = 90):\n",
    "    DataT = np.transpose(Data)\n",
    "    TrainingLen = math.ceil(len(DataT)*(TrainingPercent*0.01))         \n",
    "    PHI = np.zeros((int(TrainingLen),len(MuMatrix))) \n",
    "    BigSigInv = np.linalg.inv(BigSigma)\n",
    "    for  C in range(0,len(MuMatrix)):\n",
    "        for R in range(0,int(TrainingLen)):\n",
    "            PHI[R][C] = GetRadialBasisOut(DataT[R], MuMatrix[C], BigSigInv)\n",
    "    #print (\"PHI Generated..\")\n",
    "    return PHI\n",
    "\n",
    "def GetValTest(VAL_PHI,W):\n",
    "    Y = np.dot(W,np.transpose(VAL_PHI))\n",
    "    ##print (\"Test Out Generated..\")\n",
    "    return Y\n",
    "\n",
    "def GetErms(VAL_TEST_OUT,ValDataAct):\n",
    "    sum = 0.0\n",
    "    t=0\n",
    "    accuracy = 0.0\n",
    "    counter = 0\n",
    "    val = 0.0\n",
    "    for i in range (0,(len(VAL_TEST_OUT)-1)):\n",
    "        sum = sum + math.pow((ValDataAct[i] - VAL_TEST_OUT[i]),2)\n",
    "        if(int(np.around(VAL_TEST_OUT[i], 0)) == ValDataAct[i]):\n",
    "            counter+=1\n",
    "    accuracy = (float((counter*100))/float(len(VAL_TEST_OUT)))\n",
    "    ##print (\"Accuracy Generated..\")\n",
    "    ##print (\"Validation E_RMS : \" + str(math.sqrt(sum/len(VAL_TEST_OUT))))\n",
    "    return (str(accuracy) + ',' +  str(math.sqrt(sum/len(VAL_TEST_OUT))))\n",
    "\n",
    "def GetAccuracy(VAL_TEST_OUT,ValDataAct):\n",
    "    sum = 0.0\n",
    "    t=0\n",
    "    accuracy = 0.0\n",
    "    counter = 0\n",
    "    val = 0.0\n",
    "    for i in range (0,(len(VAL_TEST_OUT)-1)):\n",
    "        sum = sum + math.pow((ValDataAct[i] - VAL_TEST_OUT[i]),2)\n",
    "        if(int(np.around(VAL_TEST_OUT[i], 0)) == ValDataAct[i]):\n",
    "            counter+=1\n",
    "    accuracy = (float((counter*100))/float(len(VAL_TEST_OUT)))\n",
    "    return (str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 18)\n",
      "(18, 18)\n",
      "(1800, 100)\n",
      "(100,)\n",
      "(101, 100)\n",
      "(100, 100)\n"
     ]
    }
   ],
   "source": [
    "ErmsArr = []\n",
    "AccuracyArr = []\n",
    "\n",
    "#Generating clusters\n",
    "\n",
    "kmeans = KMeans(n_clusters=M, random_state=0).fit(concat_train_data)\n",
    "Mu = kmeans.cluster_centers_\n",
    "\n",
    "concat_data_T = np.array(np.transpose(concat_data))\n",
    "concat_test_data_T = np.array(np.transpose(concat_test_data))\n",
    "concat_valid_data_T = np.array(np.transpose(concat_valid_data))\n",
    "\n",
    "#Generating basis matrices\n",
    "\n",
    "BigSigma     = GenerateBigSigma(concat_data_T, Mu, TrainingPercent,IsSynthetic)\n",
    "TRAINING_PHI = GetPhiMatrix(concat_data_T, Mu, BigSigma, TrainingPercent)\n",
    "TEST_PHI     = GetPhiMatrix(concat_test_data_T, Mu, BigSigma, 100) \n",
    "VAL_PHI      = GetPhiMatrix(concat_valid_data_T, Mu, BigSigma, 100)\n",
    "W            = np.random.rand(M,)\n",
    "\n",
    "print(Mu.shape)\n",
    "print(BigSigma.shape)\n",
    "print(TRAINING_PHI.shape)\n",
    "print(W.shape)\n",
    "print(VAL_PHI.shape)\n",
    "print(TEST_PHI.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_Now        = np.dot(220, W)\n",
    "La           = 2\n",
    "learningRate = 0.01\n",
    "L_Erms_Val   = []\n",
    "L_Erms_TR    = []\n",
    "L_Erms_Test  = []\n",
    "W_Mat        = []\n",
    "TrainingTarget = (np.transpose(concat_train_vector)).flatten()\n",
    "ValDataAct = np.array(concat_valid_vector)\n",
    "TestDataAct = np.array(concat_test_vector)\n",
    "\n",
    "#Linear regression training for weights\n",
    "\n",
    "for i in range(0,1000):\n",
    "    #print ('---------Iteration: ' + str(i) + '--------------')\n",
    "    Delta_E_D     = -np.dot((TrainingTarget[i] - np.dot(np.transpose(W_Now),TRAINING_PHI[i])),TRAINING_PHI[i])\n",
    "    La_Delta_E_W  = np.dot(La,W_Now)\n",
    "    Delta_E       = np.add(Delta_E_D,La_Delta_E_W)    \n",
    "    Delta_W       = -np.dot(learningRate,Delta_E)\n",
    "    W_T_Next      = W_Now + Delta_W\n",
    "    W_Now         = W_T_Next\n",
    "    \n",
    "    #-----------------TrainingData Accuracy---------------------#\n",
    "    TR_TEST_OUT   = GetValTest(TRAINING_PHI,W_T_Next) \n",
    "    Erms_TR       = GetErms(TR_TEST_OUT,TrainingTarget)\n",
    "    Acc_TR        = GetAccuracy(TR_TEST_OUT,TrainingTarget)\n",
    "    L_Erms_TR.append(float(Erms_TR.split(',')[1]))\n",
    "    \n",
    "    #-----------------ValidationData Accuracy---------------------#\n",
    "    VAL_TEST_OUT  = GetValTest(VAL_PHI,W_T_Next) \n",
    "    Erms_Val      = GetErms(VAL_TEST_OUT,ValDataAct)\n",
    "    Acc_Val       = GetAccuracy(VAL_TEST_OUT,ValDataAct)\n",
    "    L_Erms_Val.append(float(Erms_Val.split(',')[1]))\n",
    "    \n",
    "    #-----------------TestingData Accuracy---------------------#\n",
    "    TEST_OUT      = GetValTest(TEST_PHI,W_T_Next) \n",
    "    Erms_Test     = GetErms(TEST_OUT,TestDataAct)\n",
    "    Acc_Test      = GetAccuracy(TEST_OUT,TestDataAct)\n",
    "    L_Erms_Test.append(float(Erms_Test.split(',')[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------LINEAR REGRESSION------------------------------------\n",
      "----------Gradient Descent Solution for Concatenation--------------------\n",
      "M = 100 \n",
      "Lambda  = 2\n",
      "eta = 0.01\n",
      "E_rms Training   = 0.55004843\n",
      "E_rms Validation = 0.52123634\n",
      "E_rms Testing    = 0.52497167\n",
      "Training Accuracy = 60.333333333333336%\n",
      "Validation Accuracy = 65.34653465346534%\n",
      "Testing Accuracy = 58.0%\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print ('--------------------LINEAR REGRESSION------------------------------------')\n",
    "print ('----------Gradient Descent Solution for Concatenation--------------------')\n",
    "print (\"M = 100 \\nLambda  = 2\\neta = 0.01\")\n",
    "print (\"E_rms Training   = \" + str(np.around(min(L_Erms_TR),8)))\n",
    "print (\"E_rms Validation = \" + str(np.around(min(L_Erms_Val),8)))\n",
    "print (\"E_rms Testing    = \" + str(np.around(min(L_Erms_Test),8)))\n",
    "print (\"Training Accuracy = \" + Acc_TR + \"%\")\n",
    "print (\"Validation Accuracy = \" + Acc_Val + \"%\")\n",
    "print (\"Testing Accuracy = \" + Acc_Test + \"%\")\n",
    "print ('-------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 9)\n",
      "(9, 9)\n",
      "(1800, 100)\n",
      "(100,)\n",
      "(101, 100)\n",
      "(100, 100)\n"
     ]
    }
   ],
   "source": [
    "ErmsArr = []\n",
    "AccuracyArr = []\n",
    "\n",
    "kmeans = KMeans(n_clusters=M, random_state=0).fit(diff_train_data)\n",
    "Mu = kmeans.cluster_centers_\n",
    "\n",
    "diff_data_T = np.array(np.transpose(diff_data))\n",
    "diff_test_data_T = np.array(np.transpose(diff_test_data))\n",
    "diff_valid_data_T = np.array(np.transpose(diff_valid_data))\n",
    "\n",
    "BigSigma     = GenerateBigSigma(diff_data_T, Mu, TrainingPercent,IsSynthetic)\n",
    "TRAINING_PHI = GetPhiMatrix(diff_data_T, Mu, BigSigma, TrainingPercent)\n",
    "TEST_PHI     = GetPhiMatrix(diff_test_data_T, Mu, BigSigma, 100) \n",
    "VAL_PHI      = GetPhiMatrix(diff_valid_data_T, Mu, BigSigma, 100)\n",
    "W            = np.random.rand(M,)\n",
    "\n",
    "print(Mu.shape)\n",
    "print(BigSigma.shape)\n",
    "print(TRAINING_PHI.shape)\n",
    "print(W.shape)\n",
    "print(VAL_PHI.shape)\n",
    "print(TEST_PHI.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_Now        = np.dot(220, W)\n",
    "La           = 2\n",
    "learningRate = 0.01\n",
    "L_Erms_Val   = []\n",
    "L_Erms_TR    = []\n",
    "L_Erms_Test  = []\n",
    "W_Mat        = []\n",
    "TrainingTarget = (np.transpose(diff_train_vector)).flatten()\n",
    "ValDataAct = np.array(diff_valid_vector)\n",
    "TestDataAct = np.array(diff_test_vector)\n",
    "\n",
    "for i in range(0,1000):\n",
    "    #print ('---------Iteration: ' + str(i) + '--------------')\n",
    "    Delta_E_D     = -np.dot((TrainingTarget[i] - np.dot(np.transpose(W_Now),TRAINING_PHI[i])),TRAINING_PHI[i])\n",
    "    La_Delta_E_W  = np.dot(La,W_Now)\n",
    "    Delta_E       = np.add(Delta_E_D,La_Delta_E_W)    \n",
    "    Delta_W       = -np.dot(learningRate,Delta_E)\n",
    "    W_T_Next      = W_Now + Delta_W\n",
    "    W_Now         = W_T_Next\n",
    "    \n",
    "     #-----------------TrainingData Accuracy---------------------#\n",
    "    TR_TEST_OUT   = GetValTest(TRAINING_PHI,W_T_Next) \n",
    "    Erms_TR       = GetErms(TR_TEST_OUT,TrainingTarget)\n",
    "    Acc_TR        = GetAccuracy(TR_TEST_OUT,TrainingTarget)\n",
    "    L_Erms_TR.append(float(Erms_TR.split(',')[1]))\n",
    "    \n",
    "    #-----------------ValidationData Accuracy---------------------#\n",
    "    VAL_TEST_OUT  = GetValTest(VAL_PHI,W_T_Next) \n",
    "    Erms_Val      = GetErms(VAL_TEST_OUT,ValDataAct)\n",
    "    Acc_Val       = GetAccuracy(VAL_TEST_OUT,ValDataAct)\n",
    "    L_Erms_Val.append(float(Erms_Val.split(',')[1]))\n",
    "    \n",
    "    #-----------------TestingData Accuracy---------------------#\n",
    "    TEST_OUT      = GetValTest(TEST_PHI,W_T_Next) \n",
    "    Erms_Test     = GetErms(TEST_OUT,TestDataAct)\n",
    "    Acc_Test      = GetAccuracy(TEST_OUT,TestDataAct)\n",
    "    L_Erms_Test.append(float(Erms_Test.split(',')[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------LINEAR REGRESSION----------------------------------\n",
      "----------Gradient Descent Solution for Subtraction--------------------\n",
      "M = 100 \n",
      "Lambda  = 2\n",
      "eta = 0.01\n",
      "E_rms Training   = 0.39567569\n",
      "E_rms Validation = 0.40306398\n",
      "E_rms Testing    = 0.37415786\n",
      "Training Accuracy = 60.333333333333336%\n",
      "Validation Accuracy = 53.46534653465346%\n",
      "Testing Accuracy = 69.0%\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print ('--------------------LINEAR REGRESSION----------------------------------')\n",
    "print ('----------Gradient Descent Solution for Subtraction--------------------')\n",
    "print (\"M = 100 \\nLambda  = 2\\neta = 0.01\")\n",
    "print (\"E_rms Training   = \" + str(np.around(min(L_Erms_TR),8)))\n",
    "print (\"E_rms Validation = \" + str(np.around(min(L_Erms_Val),8)))\n",
    "print (\"E_rms Testing    = \" + str(np.around(min(L_Erms_Test),8)))\n",
    "print (\"Training Accuracy = \" + Acc_TR + \"%\")\n",
    "print (\"Validation Accuracy = \" + Acc_Val + \"%\")\n",
    "print (\"Testing Accuracy = \" + Acc_Test + \"%\")\n",
    "print ('-------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(parameter):\n",
    "    return (1/(1+(np.exp(-1*parameter))))\n",
    "\n",
    "def predict(features, weights):\n",
    "    z = np.dot(features, weights)\n",
    "    answer = sigmoid(z)\n",
    "    return answer\n",
    "\n",
    "def cost_function(features, labels, weights):\n",
    "    observations = len(labels)\n",
    "\n",
    "    predictions = predict(features, weights)\n",
    "    \n",
    "    #Take the error when label=1\n",
    "    class1_cost = -labels*np.log(predictions)\n",
    "    \n",
    "    #Take the error when label=0\n",
    "    class2_cost = (1-labels)*np.log(1-predictions)\n",
    "    \n",
    "    #Take the sum of both costs\n",
    "    cost = class1_cost - class2_cost\n",
    "\n",
    "    #Take the average cost\n",
    "    cost = cost.sum()/observations\n",
    "\n",
    "    return cost\n",
    "\n",
    "def update_weights(features, labels, weights, lr):\n",
    "    \n",
    "    N = len(features)\n",
    "\n",
    "    #1 - Get Predictions\n",
    "    predictions = predict(features, weights)\n",
    "\n",
    "    #2 Transpose features \n",
    "    gradient = np.dot(features.T,  predictions - labels)\n",
    "\n",
    "    #3 Take the average cost derivative for each feature\n",
    "    gradient /= N\n",
    "\n",
    "    #4 - Multiply the gradient by our learning rate\n",
    "    gradient *= lr\n",
    "\n",
    "    #5 - Subtract from our weights to minimize cost\n",
    "    weights -= gradient\n",
    "\n",
    "    return weights\n",
    "\n",
    "def train_logistic_weight(features, labels, weights, lr, iters):\n",
    "    cost_history = []\n",
    "\n",
    "    for i in range(iters):\n",
    "        weights = update_weights(features, labels, weights, lr)\n",
    "\n",
    "        #Calculate error for auditing purposes\n",
    "        cost = cost_function(features, labels, weights)\n",
    "        cost_history.append(cost)\n",
    "\n",
    "    return weights\n",
    "\n",
    "def train_logistic_cost(features, labels, weights, lr, iters):\n",
    "    cost_history = []\n",
    "\n",
    "    for i in range(iters):\n",
    "        weights = update_weights(features, labels, weights, lr)\n",
    "\n",
    "        #Calculate error for auditing purposes\n",
    "        cost = cost_function(features, labels, weights)\n",
    "        cost_history.append(cost)\n",
    "\n",
    "    return cost_history\n",
    "\n",
    "def accuracy_Logistic(predicted_labels, actual_labels):\n",
    "    count = 0\n",
    "    a = actual_labels\n",
    "    b = np.array(predicted_labels)\n",
    "    c = np.absolute(b)\n",
    "    d = np.around(c)\n",
    "    \n",
    "    for i in range(len(a)):\n",
    "        if (a[i]  == d[i]):\n",
    "            count = count + 1\n",
    "    \n",
    "    return (1-(count/len(a)))*100\n",
    "\n",
    "def Erms_Logistic(VAL_TEST_OUT,cost_last):\n",
    "    return (math.sqrt(2*cost_last/len(VAL_TEST_OUT)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_Logistic        = np.dot(220, W_Now)\n",
    "concat_data_T = np.array(np.transpose(concat_data))\n",
    "concat_test_data_T = np.array(np.transpose(concat_test_data))\n",
    "concat_valid_data_T = np.array(np.transpose(concat_valid_data))\n",
    "\n",
    "kmeans = KMeans(n_clusters=M, random_state=0).fit(concat_train_data)\n",
    "Mu = kmeans.cluster_centers_\n",
    "\n",
    "BigSigma     = GenerateBigSigma(concat_data_T, Mu, TrainingPercent,IsSynthetic)\n",
    "TRAINING_PHI = GetPhiMatrix(concat_data_T, Mu, BigSigma, TrainingPercent)\n",
    "TEST_PHI     = GetPhiMatrix(concat_test_data_T, Mu, BigSigma, 100) \n",
    "VAL_PHI      = GetPhiMatrix(concat_valid_data_T, Mu, BigSigma, 100)\n",
    "\n",
    "TrainingTarget = (np.transpose(concat_train_vector)).flatten()\n",
    "ValDataAct = np.array(concat_valid_vector)\n",
    "TestDataAct = np.array(concat_test_vector)\n",
    "\n",
    "current_w = train_logistic_weight(TRAINING_PHI,TrainingTarget,W_Logistic,0.01,2000)\n",
    "current_cost_hist = train_logistic_cost(TRAINING_PHI,TrainingTarget,W_Logistic,0.01,2000)\n",
    "\n",
    "#-----------------TrainingData---------------------#\n",
    "TR_TEST_OUT   = GetValTest(TRAINING_PHI,current_w) \n",
    "Erms_TR       = Erms_Logistic(TR_TEST_OUT,current_cost_hist[-1])\n",
    "Acc_TR        = accuracy_Logistic(TR_TEST_OUT,TrainingTarget)\n",
    "        \n",
    "#-----------------ValidationData---------------------#\n",
    "VAL_TEST_OUT  = GetValTest(VAL_PHI,current_w) \n",
    "Erms_Val      = Erms_Logistic(VAL_TEST_OUT,current_cost_hist[-1])\n",
    "Acc_Val       = accuracy_Logistic(VAL_TEST_OUT,ValDataAct)\n",
    "    \n",
    "#-----------------TestingData---------------------#\n",
    "TEST_OUT      = GetValTest(TEST_PHI,current_w) \n",
    "Erms_Test     = Erms_Logistic(TEST_OUT,current_cost_hist[-1])\n",
    "Acc_Test      = accuracy_Logistic(TEST_OUT,TestDataAct)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------LOGISTIC REGRESSION------------------------------------\n",
      "----------Gradient Descent Solution for Concatenation--------------------\n",
      "M = 100 \n",
      "Iteration  = 2000\n",
      "eta = 0.01\n",
      "E_rms Training   = 0.026592186861667606\n",
      "E_rms Validation = 0.11226118430927072\n",
      "E_rms Testing    = 0.11282109393878988\n",
      "Training Accuracy = 79.44444444444446%\n",
      "Validation Accuracy = 81.0%\n",
      "Testing Accuracy = 79.0%\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print ('--------------------LOGISTIC REGRESSION------------------------------------')\n",
    "print ('----------Gradient Descent Solution for Concatenation--------------------')\n",
    "print (\"M = 100 \\nIteration  = 2000\\neta = 0.01\")\n",
    "print (\"E_rms Training   = \" + str(Erms_TR))\n",
    "print (\"E_rms Validation = \" + str(Erms_Val))\n",
    "print (\"E_rms Testing    = \" + str(Erms_Test))\n",
    "print (\"Training Accuracy = \" + str(Acc_TR) + \"%\")\n",
    "print (\"Validation Accuracy = \" + str(Acc_Val) + \"%\")\n",
    "print (\"Testing Accuracy = \" + str(Acc_Test) + \"%\")\n",
    "print ('-------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_Logistic        = np.dot(220, W_Now)\n",
    "diff_data_T = np.array(np.transpose(diff_data))\n",
    "diff_test_data_T = np.array(np.transpose(diff_test_data))\n",
    "diff_valid_data_T = np.array(np.transpose(diff_valid_data))\n",
    "\n",
    "kmeans = KMeans(n_clusters=M, random_state=0).fit(diff_train_data)\n",
    "Mu = kmeans.cluster_centers_\n",
    "\n",
    "BigSigma     = GenerateBigSigma(diff_data_T, Mu, TrainingPercent,IsSynthetic)\n",
    "TRAINING_PHI = GetPhiMatrix(diff_data_T, Mu, BigSigma, TrainingPercent)\n",
    "TEST_PHI     = GetPhiMatrix(diff_test_data_T, Mu, BigSigma, 100) \n",
    "VAL_PHI      = GetPhiMatrix(diff_valid_data_T, Mu, BigSigma, 100)\n",
    "\n",
    "TrainingTarget = (np.transpose(diff_train_vector)).flatten()\n",
    "ValDataAct = np.array(diff_valid_vector)\n",
    "TestDataAct = np.array(diff_test_vector)\n",
    "\n",
    "current_w = train_logistic_weight(TRAINING_PHI,TrainingTarget,W_Logistic,0.01,2000)\n",
    "current_cost_hist = train_logistic_cost(TRAINING_PHI,TrainingTarget,W_Logistic,0.01,2000)\n",
    "\n",
    "#-----------------TrainingData---------------------#\n",
    "TR_TEST_OUT   = GetValTest(TRAINING_PHI,current_w) \n",
    "Erms_TR       = Erms_Logistic(TR_TEST_OUT,current_cost_hist[-1])\n",
    "Acc_TR        = accuracy_Logistic(TR_TEST_OUT,TrainingTarget)\n",
    "        \n",
    "#-----------------ValidationData---------------------#\n",
    "VAL_TEST_OUT  = GetValTest(VAL_PHI,current_w) \n",
    "Erms_Val      = Erms_Logistic(VAL_TEST_OUT,current_cost_hist[-1])\n",
    "Acc_Val       = accuracy_Logistic(VAL_TEST_OUT,ValDataAct)\n",
    "    \n",
    "#-----------------TestingData---------------------#\n",
    "TEST_OUT      = GetValTest(TEST_PHI,current_w) \n",
    "Erms_Test     = Erms_Logistic(TEST_OUT,current_cost_hist[-1])\n",
    "Acc_Test      = accuracy_Logistic(TEST_OUT,TestDataAct)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------LOGISTIC REGRESSION------------------------------------\n",
      "----------Gradient Descent Solution for Subtraction--------------------\n",
      "M = 100 \n",
      "Iteration  = 2000\n",
      "eta = 0.01\n",
      "E_rms Training   = 0.025854365414105986\n",
      "E_rms Validation = 0.10914640815554848\n",
      "E_rms Testing    = 0.1096907826455357\n",
      "Training Accuracy = 75.94444444444444%\n",
      "Validation Accuracy = 69.0%\n",
      "Testing Accuracy = 73.0%\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print ('--------------------LOGISTIC REGRESSION------------------------------------')\n",
    "print ('----------Gradient Descent Solution for Subtraction--------------------')\n",
    "print (\"M = 100 \\nIteration  = 2000\\neta = 0.01\")\n",
    "print (\"E_rms Training   = \" + str(Erms_TR))\n",
    "print (\"E_rms Validation = \" + str(Erms_Val))\n",
    "print (\"E_rms Testing    = \" + str(Erms_Test))\n",
    "print (\"Training Accuracy = \" + str(Acc_TR) + \"%\")\n",
    "print (\"Validation Accuracy = \" + str(Acc_Val) + \"%\")\n",
    "print (\"Testing Accuracy = \" + str(Acc_Test) + \"%\")\n",
    "print ('-------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Placeholder\n",
    "inputTensor  = tf.placeholder(tf.float32, [None, 18])\n",
    "outputTensor = tf.placeholder(tf.float32, [None, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_HIDDEN_NEURONS_LAYER_1 = 100\n",
    "NUM_HIDDEN_NEURONS_LAYER_2 = 100\n",
    "\n",
    "LEARNING_RATE = 1\n",
    "\n",
    "# Initializing the weights to Normal Distribution\n",
    "def init_weights(shape):\n",
    "    return tf.Variable(tf.random_normal(shape,stddev=0.01))\n",
    "\n",
    "#2 hidden layer\n",
    "input_hidden_weights  = init_weights([18, NUM_HIDDEN_NEURONS_LAYER_1])\n",
    "\n",
    "#initializing the hidden layer 1 to output layer weights 1\n",
    "hidden_output_weights1 = init_weights([NUM_HIDDEN_NEURONS_LAYER_1, NUM_HIDDEN_NEURONS_LAYER_2])\n",
    "\n",
    "#initializing the input to hidden layer 2 weights\n",
    "input_hidden_weights2 = init_weights([NUM_HIDDEN_NEURONS_LAYER_1, NUM_HIDDEN_NEURONS_LAYER_2])\n",
    "\n",
    "#initializing the output to hidden layer 2 weights\n",
    "hidden_output_weights2 = init_weights([NUM_HIDDEN_NEURONS_LAYER_2, 1])\n",
    "\n",
    "# Computing values at the hidden layer 1\n",
    "hidden_layer1 = tf.nn.relu(tf.matmul(inputTensor, input_hidden_weights))\n",
    "\n",
    "#computing values at the hidden layer 2\n",
    "hidden_layer2 = tf.nn.relu(tf.matmul(hidden_layer1, input_hidden_weights2))\n",
    "\n",
    "# Computing values at the output layer\n",
    "output_layer = tf.matmul(hidden_layer2, hidden_output_weights2)\n",
    "\n",
    "# Defining Error Function\n",
    "error_function = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=output_layer, labels=outputTensor))\n",
    "\n",
    "# Defining Learning Algorithm and Training Parameters\n",
    "training = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(error_function)\n",
    "\n",
    "# Prediction Function\n",
    "prediction = tf.round(tf.sigmoid(output_layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "534a7ccf1ff84ac282653444d5412d6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arinj\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\arinj\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "NUM_OF_EPOCHS = 5000\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "processedTrainingData = np.array(concat_train_data)\n",
    "processedTrainingLabel = np.array(concat_train_vector)\n",
    "processedTestingData = np.array(concat_test_data)\n",
    "processedTestingLabel = np.array(concat_test_vector)\n",
    "\n",
    "training_accuracy = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Set Global Variables ?\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    for epoch in tqdm_notebook(range(NUM_OF_EPOCHS)):\n",
    "        \n",
    "        #Shuffle the Training Dataset at each epoch\n",
    "        p = np.array(np.random.permutation(range(len(processedTrainingData)-1)),dtype='int')\n",
    "        processedTrainingData  = processedTrainingData[p]\n",
    "        processedTrainingLabel = processedTrainingLabel[p]\n",
    "        \n",
    "        # Start batch training\n",
    "        for start in range(0, len(processedTrainingData), BATCH_SIZE):\n",
    "            end = start + BATCH_SIZE\n",
    "            sess.run(training, feed_dict={inputTensor: processedTrainingData[start:end], \n",
    "                                          outputTensor: processedTrainingLabel[start:end]})\n",
    "        # Training accuracy for an epoch\n",
    "        training_accuracy.append(np.mean(np.argmax(processedTrainingLabel, axis=1) ==\n",
    "                             sess.run(prediction, feed_dict={inputTensor: processedTrainingData,\n",
    "                                                             outputTensor: processedTrainingLabel})))\n",
    "    # Testing\n",
    "    predictedTestLabel = sess.run(prediction, feed_dict={inputTensor: processedTestingData})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e87e72da20>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df['acc'] = training_accuracy\n",
    "df.plot(grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------NEURAL NETWORKS------------------------------------\n",
      "---------------------Concatenation-------------------------------------\n",
      "Errors: 0  Correct :100\n",
      "Testing Accuracy: 100.0%\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "wrong   = 0\n",
    "right   = 0\n",
    "predictedTestLabelList = []\n",
    "\n",
    "\"\"\n",
    "for i,j in zip(processedTestingLabel,predictedTestLabel):\n",
    "    #predictedTestLabelList.append(decodeLabel(j))\n",
    "    \n",
    "    if np.argmax(i) == j:\n",
    "        right = right + 1\n",
    "    else:\n",
    "        wrong = wrong + 1\n",
    "print ('--------------------NEURAL NETWORKS------------------------------------')\n",
    "print ('---------------------Concatenation-------------------------------------')\n",
    "\n",
    "print(\"Errors: \" + str(wrong), \" Correct :\" + str(right))\n",
    "\n",
    "print(\"Testing Accuracy: \" + str(right/(right+wrong)*100) + \"%\")\n",
    "print('-------------------------------------------------------------------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Placeholder\n",
    "inputTensor  = tf.placeholder(tf.float32, [None, 9])\n",
    "outputTensor = tf.placeholder(tf.float32, [None, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_HIDDEN_NEURONS_LAYER_1 = 100\n",
    "NUM_HIDDEN_NEURONS_LAYER_2 = 100\n",
    "\n",
    "LEARNING_RATE = 1\n",
    "\n",
    "# Initializing the weights to Normal Distribution\n",
    "def init_weights(shape):\n",
    "    return tf.Variable(tf.random_normal(shape,stddev=0.01))\n",
    "\n",
    "#2 hidden layer\n",
    "input_hidden_weights  = init_weights([9, NUM_HIDDEN_NEURONS_LAYER_1])\n",
    "\n",
    "#initializing the hidden layer 1 to output layer weights 1\n",
    "hidden_output_weights1 = init_weights([NUM_HIDDEN_NEURONS_LAYER_1, NUM_HIDDEN_NEURONS_LAYER_2])\n",
    "\n",
    "#initializing the input to hidden layer 2 weights\n",
    "input_hidden_weights2 = init_weights([NUM_HIDDEN_NEURONS_LAYER_1, NUM_HIDDEN_NEURONS_LAYER_2])\n",
    "\n",
    "#initializing the output to hidden layer 2 weights\n",
    "hidden_output_weights2 = init_weights([NUM_HIDDEN_NEURONS_LAYER_2, 1])\n",
    "\n",
    "# Computing values at the hidden layer 1\n",
    "hidden_layer1 = tf.nn.relu(tf.matmul(inputTensor, input_hidden_weights))\n",
    "\n",
    "#computing values at the hidden layer 2\n",
    "hidden_layer2 = tf.nn.relu(tf.matmul(hidden_layer1, input_hidden_weights2))\n",
    "\n",
    "# Computing values at the output layer\n",
    "output_layer = tf.matmul(hidden_layer2, hidden_output_weights2)\n",
    "\n",
    "# Defining Error Function\n",
    "error_function = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=output_layer, labels=outputTensor))\n",
    "\n",
    "# Defining Learning Algorithm and Training Parameters\n",
    "training = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(error_function)\n",
    "\n",
    "# Prediction Function\n",
    "prediction = tf.round(tf.sigmoid(output_layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bde503c8beeb481d8a946125f53fa249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arinj\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\arinj\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "NUM_OF_EPOCHS = 5000\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "processedTrainingData = np.array(diff_train_data)\n",
    "processedTrainingLabel = np.array(diff_train_vector)\n",
    "processedTestingData = np.array(diff_test_data)\n",
    "processedTestingLabel = np.array(diff_test_vector)\n",
    "\n",
    "training_accuracy = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Set Global Variables ?\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    for epoch in tqdm_notebook(range(NUM_OF_EPOCHS)):\n",
    "        \n",
    "        #Shuffle the Training Dataset at each epoch\n",
    "        p = np.array(np.random.permutation(range(len(processedTrainingData)-1)),dtype='int')\n",
    "        processedTrainingData  = processedTrainingData[p]\n",
    "        processedTrainingLabel = processedTrainingLabel[p]\n",
    "        \n",
    "        # Start batch training\n",
    "        for start in range(0, len(processedTrainingData), BATCH_SIZE):\n",
    "            end = start + BATCH_SIZE\n",
    "            sess.run(training, feed_dict={inputTensor: processedTrainingData[start:end], \n",
    "                                          outputTensor: processedTrainingLabel[start:end]})\n",
    "        # Training accuracy for an epoch\n",
    "        training_accuracy.append(np.mean(np.argmax(processedTrainingLabel, axis=1) ==\n",
    "                             sess.run(prediction, feed_dict={inputTensor: processedTrainingData,\n",
    "                                                             outputTensor: processedTrainingLabel})))\n",
    "    # Testing\n",
    "    predictedTestLabel = sess.run(prediction, feed_dict={inputTensor: processedTestingData})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e80089d780>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df['acc'] = training_accuracy\n",
    "df.plot(grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------NEURAL NETWORKS------------------------------------\n",
      "-----------------------Subtraction-------------------------------------\n",
      "Errors: 32  Correct :68\n",
      "Testing Accuracy: 68.0%\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "wrong   = 0\n",
    "right   = 0\n",
    "predictedTestLabelList = []\n",
    "\n",
    "\"\"\n",
    "for i,j in zip(processedTestingLabel,predictedTestLabel):\n",
    "    #predictedTestLabelList.append(decodeLabel(j))\n",
    "    \n",
    "    if np.argmax(i) == j:\n",
    "        right = right + 1\n",
    "    else:\n",
    "        wrong = wrong + 1\n",
    "print ('--------------------NEURAL NETWORKS------------------------------------')\n",
    "print ('-----------------------Subtraction-------------------------------------')\n",
    "\n",
    "print(\"Errors: \" + str(wrong), \" Correct :\" + str(right))\n",
    "\n",
    "print(\"Testing Accuracy: \" + str(right/(right+wrong)*100) +\"%\")\n",
    "print('-------------------------------------------------------------------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------\n",
      "------------------------THE END-----------------------------------------\n",
      "-------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('-------------------------------------------------------------------------')\n",
    "print('-------------------------------------------------------------------------')\n",
    "print ('------------------------THE END-----------------------------------------')\n",
    "print('-------------------------------------------------------------------------')\n",
    "print('-------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
